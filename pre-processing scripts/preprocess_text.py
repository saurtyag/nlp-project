# -*- coding: utf-8 -*-
"""preprocess_text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RHu9BGW_R98bHB1UKeHr9jtUEBIWOhyQ
"""
"""
Code to do pre-processing of the 8-k files 
there are 477 companies
The companies have been extracted from the govt website
It is based on the paper by Dan Jurafsky

"""


import pandas as pd 
import nltk 
from nltk.corpus import stopwords 
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer 
from nltk.stem.porter import PorterStemmer
from bs4 import BeautifulSoup
import nltk

dataFrame = pd.read_csv("/content/drive/My Drive/ABT.csv")

#function to remove HTML 
import re
import string 
#remove HTML tag and elements
def removeHTML(text):
  clean_text = re.compile('<.*?>')
  clean_text = re.sub(clean_text,'',text)
  return clean_text

#removing punctunation block
def removePunc(text):
  no_punc_text = "".join([c for c in text if c not in string.punctuation])
  return no_punc_text

from collections import Counter
  

#remove stop words 
def removeStopWords(text):
  stop_words = stopwords.words('english')
  stopwords_dict = Counter(stop_words)
  text = ' '.join([word for word in text.split() if word not in stopwords_dict])
  return text

#remove spaces
def spaceRemoval(text):
  new_text = " ".join(re.split("\s+",text,flags=re.UNICODE))
  return new_text

from stemming.porter2 import stem
  
def stemmingOfWords(text):
  stem_words = [" ".join([stem(word) for word in text.split(" ")])]
  stem_words = " ".join(stem_words)
  return stem_words

#reducing content based on position passed
def contentReducerHead(text,key_word):
    head,sep,tail = text.partition(key_word)
    if not tail:
      return text
    else:
      return tail

def contentReducerTail(text,key_word):
    head,sep,tail = text.partition(key_word)
    if not head:
      return text
    else:
      return head

for i in range(len(dataFrame['text'])):
  text = dataFrame['text'][i]
  text = contentReducerHead(text,'ITEM INFORMATION')
  text = contentReducerTail(text,'GRAPHIC')
  text = str(text)
  clean_text = removeHTML(text)
  clean_text = spaceRemoval(clean_text)
  clean_text = removePunc(clean_text)
  clean_text = removeStopWords(clean_text)
  words_without_stem = clean_text

  stemed_words = stemmingOfWords(clean_text)
  stemed_words = stemed_words.lower()

  words_without_stem = words_without_stem.lower()

  dataFrame['Words_Without_Stem'][i] = words_without_stem
  dataFrame['Stemed_Words'][i] = stemed_words

  

dataFrame.to_csv('modified_file.csv')